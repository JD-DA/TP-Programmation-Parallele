{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TP1 Premiers pas avec OpenMP\n## M1 informatique, Université d'Orléans 2021/2022"},{"metadata":{},"cell_type":"markdown","source":"*L'objectif de ce TP est de découvrir [OpenMP](https://www.openmp.org/) en expérimentant les différentes directives depuis les plus bas niveaux jusqu'aux constructions les plus sophistiquées autour des boucles.*\n\n### 0. Fiches de TP"},{"metadata":{},"cell_type":"markdown","source":"Les énoncés des TP sont fournis sous forme de *notebook Jupyter*. Il s'agit de documents modifiables. Lorsque le document est visualisé dans un navigateur web, des menus (et éventuellement une barre d'outil si elle est activée) permettent de manipuler le document."},{"metadata":{},"cell_type":"markdown","source":"Le document est composé d'une suite de cellules qui peuvent contenir du texte mis en forme au [format Markdown](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd), du code Python ou encore du texte brut. Ces cellules peuvent être *déplacées*, de nouvelles cellules **insérées**, etc."},{"metadata":{"lines_to_next_cell":2,"tags":["question"]},"cell_type":"raw","source":"Q0. Les énoncés comportent des zones question (comme celle-ci) dans lesquelles écrire vos réponses. Prenez le temps de répondre à chacune de ces questions, c'est le meilleur moyen de bien assimiler le TP.\n\nSi ce n'est pas déjà fait, activez l'affichage de la barre d'outils.\n\nEn observant les menus et le code source des cellules précédentes, expliquez comment il est possible :\n - d'insérer une cellule de texte Markdown :\n\n - d'exécuter une cellule Markdown pour passer du code source à la vue formattée :\n\n - de mettre en gras un passage :\n\n - d'insérer un lien vers une page web : \n\n"},{"metadata":{},"cell_type":"markdown","source":"*PS. Pour ceux d'entre nous qui préférent travailler en mode texte ou dans un terminal, il est possible de travailler sur le source de la fiche de TP. On perd simplement la possibilité d'exécuter directement du code Python au fil de l'eau dans la fiche.*"},{"metadata":{},"cell_type":"markdown","source":"## 1. Hello parallel world!"},{"metadata":{},"cell_type":"markdown","source":"Pour cette première partie, il suffit de disposer d'un compilateur C++ avec support pour OpenMP, d'un terminal ouvert et d'un éditeur de fichiers."},{"metadata":{},"cell_type":"markdown","source":"Commençons par créer un fichier `Makefile` pour préciser quel compilateur utiliser et quels arguments lui passer à la compilation. Nous n'écrirons pas de règles, notre source n'ayant aucune dépendance, les règles implicites suffiront pour compiler notre programme."},{"metadata":{},"cell_type":"markdown","source":"```make\nCXX=g++\nCXXFLAGS=-std=c++11 -Wall -Wextra -pedantic -fopenmp\n```"},{"metadata":{},"cell_type":"markdown","source":"Et voici notre premier programme OpenMP `hello.cpp`"},{"metadata":{},"cell_type":"markdown","source":"~~~c++\n#include <iostream>\n#include <omp.h>\nusing namespace std;\n\nint main(int, char *[])\n{\n    cout << \"Bonjour\" << endl;\n    cout << \"Nous sommes \" << omp_get_num_threads() << \" threads dans cette équipe\" << endl;\n    cout << \"Au revoir\" << endl;\n}\n~~~"},{"metadata":{},"cell_type":"markdown","source":"Si tout se passe bien, la commande `make hello` devrait compiler ce programme et sans surprise au lancement on obtient un comportement très séquentiel."},{"metadata":{},"cell_type":"markdown","source":"```\n$ ./hello \nBonjour\nNous sommes 1 threads dans cette équipe\nAu revoir\n```"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q1. Relancez la commande en plaçant `TRUE` dans la variable d'environnement `OMP_DISPLAY_ENV` et copiez ici le résultat. Ce sont les valeurs par défaut des paramètres configurables depuis l'environnement d'exécution.\n\n```\n$ OMP_DISPLAY_ENV=TRUE ./hello\n```\n"},{"metadata":{},"cell_type":"markdown","source":"### 1.1. pragma omp parallel"},{"metadata":{},"cell_type":"markdown","source":"La directive `#pragma omp parallel` indique que l'instruction (ou le bloc d'instructions) qui suit doit être exécuté par une équipe de *threads* (souvenez-vous qu'openMP repose sur le paradigme de programmation parallèle [fork-join](https://en.wikipedia.org/wiki/Fork–join_model))."},{"metadata":{"lines_to_next_cell":2,"tags":["question"]},"cell_type":"raw","source":"Q2. Ajoutez la directive `#pragma omp parallel` juste avant la ligne qui affiche `Bonjour` puis recompilez et exécutez le programme `hello`. Quelle sortie obtenez-vous ? Pourquoi autant de fois `Bonjour` et si peu de fois `Au revoir` ?\n\n\nModifiez le programme pour que ce soit tout le bloc d'affichage `Bonjour` + `Au revoir` qui soit parallélisé. Quel affichage obtenez-vous ? Reste-t-il identique si vous relancez le programme ?\n\n"},{"metadata":{},"cell_type":"markdown","source":"La fonction de bibliothèque `omp_get_num_threads` permet de connaître le nombre total de *threads* dans l'équipe et la fonction `omp_get_thread_num` indique le numéro du *thread* courant. "},{"metadata":{},"cell_type":"markdown","source":"La variable d'environnement `OMP_NUM_THREADS` permet de spécifier le nombre de *threads* souhaités. *Il est aussi possible d'utiliser la fonction de la bibliothèque `omp_set_num_threads` mais l'utilisation d'une variable d'environnement permet de changer la valeur plus facilement sans recompiler le programme.*"},{"metadata":{},"cell_type":"markdown","source":"*Les variables déclarées à l'intérieur d'un bloc parallèle sont par défaut privées : chaque thread dispose de sa propre variable. Les variables déclarées à l'extérieur d'un bloc parallèle et celles allouées sur le tas sont partagées par tous les threads de l'équipe.*"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q3. Modifiez votre programme pour que chaque thread stocke son identifiant et le nombre total de *threads* dans des variables `id` et `np` puis affichez `Bonjour(13/54)` puis `Au revoir(13/54)` où `54` est remplacé par le nombre de *threads* de l'équipe et `13` par le numéro du *thread* courant. Quelle commande pour lancer le programme avec 32 *threads* ? Quel affichage obtenez-vous ?\n\n"},{"metadata":{},"cell_type":"markdown","source":"### 1.2. pragma omp critical, single, barrier"},{"metadata":{},"cell_type":"markdown","source":"La directive `#pragma omp critical` définit une section critique, une portion de code qui ne peut être accédée par les *threads* qu'un seul à la fois."},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q4. Modifiez votre programme pour que les affichages ne s'entremêlent pas : associer une section critique à chaque ligne d'affichage.\n\n"},{"metadata":{},"cell_type":"markdown","source":"La directive `#pragma omp barrier` définit une barrière de synchronisation, un rendez-vous que tous les *threads* doivent avoir rejoint avant d'être autorisés à poursuivre leur exécution."},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q5. Modifiez votre programme pour que personne ne dise `au revoir` avant que tout le monde n'ait terminé de dire `bonjour` !\n\n"},{"metadata":{},"cell_type":"markdown","source":"La directive `#pragma omp single` définit une section de code qui sera exécutée par un unique *thread*."},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q6. Modifiez votre programme pour qu'un seul thread annonce le nombre de threads de l'équipe une fois que tout le monde a dit `bonjour` et qu'un second thread (pas nécessairement le même) annonce la fin du TP ensuite, avant que tout le monde dise `au revoir`. N'oubliez pas de faire en sorte que ces threads qui parlent annoncent leur `id`.\n\n"},{"metadata":{},"cell_type":"markdown","source":"### 1.3. On récapitule et on mesure le temps de calcul !"},{"metadata":{},"cell_type":"markdown","source":"Voici un programme `syracuse.cpp` que nous allons paralléliser. Il utilise la fonction de bibliothèque `omp_get_wtime` pour mesurer le temps réel écoulé entre deux points du programme."},{"metadata":{},"cell_type":"markdown","source":"~~~c++\n#include <iostream>\n#include <omp.h>\nusing namespace std;\n\n#define TOTAL 2000000\n\nint main(int, char *[])\n{\n    int pass=0, cur;\n    double start = omp_get_wtime();\n///////////////////// MODIFIER A PARTIR D'ICI UNIQUEMENT /////////////////////\n    for(int i=0; i<TOTAL; i++) {\n        cur=i;\n        while (cur>1)\n            cur=cur%2?3*cur+1:cur/2;\n        pass++;\n    }\n///////////////////// MODIFIER JUSQU'ICI UNIQUEMENT /////////////////////\n    double end = omp_get_wtime();\n    cout << pass << \" out of \" << TOTAL << \"! (delta=\" << TOTAL-pass << \")\" << endl;\n    cout << \"ellapsed time: \" << (end-start)*1000 << \"ms\" << endl;\n}\n~~~"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q7. Compilez et exécutez le programme. Vérifiez que la variable `pass` doit être égale à `TOTAL` en fin de programme. Si besoin, modifier la valeur de `TOTAL` pour avoir un temps d'exécution de l'ordre de `1000ms`.\n\n"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q8. En utilisant **uniquement les directives vues ci-dessus**, parallélisez ce programme. Attention, le comportement du programme doit toujours être le même, il s'agit de répartir le travail entre plusieurs *threads* ! Si besoin, utilisez des sections critiques pour protéger l'accès aux variables partagées. Attention à la variable `cur` qui mérite sans doute une version privée par `thread` !\n\n"},{"metadata":{},"cell_type":"markdown","source":"Si votre programme effectue une section critique à chaque passage dans la boucle... il est certainement peu efficace et la parallélisation peut même aller jusqu'à dégrader le temps de calcul par rapport au séquentiel !"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q9. Ajoutez une variable privée `mycur` par thread et effectuez une unique section critique pour mettre à jour `pass` après la boucle. Exécutez le programme et observez le gain de temps ! L'accélération obtenue est-elle égale au nombre de threads ? Pourquoi ?\n\n"},{"metadata":{},"cell_type":"markdown","source":"*PS. On pourra s'aider d'une boucle shell comme ceci :*\n```\n$ for np in 1 2 4 8 16; do OMP_NUM_THREADS=$np ./syracuse; done\n```"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"CHECK-POINT #1 <<<<<<< LORSQUE VOUS ATTEIGNEZ CETTE ENDROIT DE LA FICHE, APPELEZ VOTRE CHARGÉ DE TP ! >>>>>>>>"},{"metadata":{},"cell_type":"markdown","source":"## 2. Vers l'infini et au-delà"},{"metadata":{},"cell_type":"markdown","source":"Dans cette deuxième partie, nous allons paralléliser un code existant. Téléchargez et décompressez l'archive\n`astro.tar.gz` fournie avec le TP. **Lire le fichier `README.md`** — dans un premier temps, vous pouvez laisser de côté la partie `bench` et `show` qui servira à effectuer des mesures de performance."},{"metadata":{},"cell_type":"markdown","source":"Le programme à paralléliser prend en entrée une image au format [FITS](https://fr.wikipedia.org/wiki/Flexible_Image_Transport_System) $\\operatorname{Astro}$ et produit en sortie une image $\\operatorname{Resca}$ au format [PGM](https://fr.wikipedia.org/wiki/Portable_pixmap) produite par une mise à l'échelle comme ceci :"},{"metadata":{},"cell_type":"markdown","source":"$$\n\\forall i,j,\\quad \\operatorname{Resca}(i,j) = 255\\frac{\\operatorname{Astro}(i,j)-m}{M-m}\\qquad\\mbox{où }\n\\begin{cases}M=\\max_{i,j}\\operatorname{Astro}(i,j) \\\\ m=\\min_{i,j}\\operatorname{Astro}(i,j)\\end{cases}\n$$"},{"metadata":{},"cell_type":"markdown","source":"Ces calculs sont effectués dans la partie du code qui est à modifier :"},{"metadata":{},"cell_type":"markdown","source":"~~~c++\n    ///////////////////// MODIFIER A PARTIR D'ICI UNIQUEMENT /////////////////\n    for (j = 0; j < astro.height(); j++)\n      for (i = 0; i < astro.width(); i++) {\n        amin = min(amin, astro(i, j));\n        amax = max(amax, astro(i, j));\n      }\n    unsigned short arange = amax - amin;\n    for (j = 0; j < astro.height(); j++)\n      for (i = 0; i < astro.width(); i++)\n        resca(i, j) = (astro(i, j) - amin) * 255 / arange;\n    ///////////////////// MODIFIER JUSQU'ICI UNIQUEMENT /////////////////////\n~~~\n"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q10. Compilez et exécutez le programme `linear` en suivant les instructions du fichier `README.md`. Visualisez l'image obtenue et copiez là dans un fichier `resca-ref.pgm`.\n\n\nDans le code ci-dessus il y a deux boucles. Laquelle vous semble la plus facile à paralléliser ? Quel est le rôle des variables `amin`, `amax` et `arange` ?\n\n"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q11. En utilisant **uniquement les directives vues en partie 1**, parallélisez ce programme en créant deux régions parallèles, une autour de chaque bloc de boucles. Testez votre programme avec `10` itérations et comparez son temps de calcul à la version séquentielle.  \n\nVérifiez que l'image produite est bien identique à la version séquentielle !\n"},{"metadata":{},"cell_type":"markdown","source":"**Astuce.** Pour comparer les deux images `resca-ref.pgm` et `resca.pgm`, vous pouvez utiliser par exemple l'outil de comparaison de *Image Magick* ou *Graphics Magick* si vous en disposez :\n\n```\n$ compare /tmp/resca-ref.pgm /tmp/resca.pgm /tmp/diff.png && xdg-open /tmp/diff.png\n$ magick compare /tmp/resca-ref.pgm /tmp/resca.pgm /tmp/diff.png && xdg-open /tmp/diff.png\n$ gm compare /tmp/resca-ref.pgm /tmp/resca.pgm /tmp/diff.png && xdg-open /tmp/diff.png\n```\n\nSinon vous pouvez de manière plus minimaliste et comparer les empreintes des deux fichiers pour tester leur égalité :\n\n```\n$ shasum /tmp/resca-ref.pgm /tmp/resca.pgm\n```"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. pragma omp for, collapse"},{"metadata":{},"cell_type":"markdown","source":"Les boucles sont tellement fréquentes dans le code numérique à paralléliser qu'OpenMP dispose de directives dédiées à cette tâche. Ainsi `#pragma omp for` distribue les indices de la boucle qui suit la directive entre les différents *threads* de l'équipe et nous libère des fastidieux calculs associés."},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q12. Simplifiez votre code parallèle pour utiliser un `#pragma omp for` devant les boucles indicées par `j` de chaque région. OpenMP s'occupe de privatiser la variable de boucle mais attention aux autres variables ! *En particulier il faut veiller à calculer le minimum et le maximum correctement avec une section critique.*\n\nVérifiez que l'image produite est bien identique à la version séquentielle !\n"},{"metadata":{},"cell_type":"markdown","source":"Lorsque plusieurs boucles sont imbriquées, la clause `collapse(N)` permet de paralléliser simultanément les `N` premiers niveaux de boucles. Dans notre exemple il peut être pertinent de traiter les deux boucles simultanément."},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q13. Modifiez votre programme pour paralléliser les deux niveaux de boucle simultanément.\n\nVérifiez que l'image produite est bien identique à la version séquentielle !\n"},{"metadata":{},"cell_type":"markdown","source":"### 2.2. reduction"},{"metadata":{},"cell_type":"markdown","source":"Notre premier bloc de boucles imbriquées calcule un minimum et un maximum. Effectuer ce calcul dans chaque *thread* avant de mettre en commun le résultat est une opération très courante. OpenMP permet d'automatiser cette phase grâce à la clause `reduction(op:var)` où `op` est l'opération qu'on souhaite réduire et `var` la variable où stocker le résultat."},{"metadata":{"lines_to_next_cell":2,"tags":["question"]},"cell_type":"raw","source":"Q14. Modifiez votre programme pour simplifier le calcul de `amin` et `amax` grâce à `reduction`.\n\nVérifiez que l'image produite est bien identique à la version séquentielle !\n"},{"metadata":{},"cell_type":"markdown","source":"Enfin, il est possible de contracter les directives `#pragma omp parallel` et `#pragma omp for` lorsqu'elles se suivent en un unique `#pragma omp parallel for`."},{"metadata":{"lines_to_next_cell":2,"tags":["question"]},"cell_type":"raw","source":"Q15. Modifiez votre programme pour que la seule différence entre la version séquentielle et la version parallèle soit l'ajout d'une directive en tête de chaque bloc de boucles.\n\nVérifiez que l'image produite est bien identique à la version séquentielle !\n"},{"metadata":{},"cell_type":"markdown","source":"### 2.3. schedule"},{"metadata":{},"cell_type":"markdown","source":"La manière dont les *threads* se partagent les indices impacte les performances du calcul. OpenMP permet de choisir une stratégie de distribution des indices à travers la clause `schedule(S)` où `S` décrit la politique à appliquer. Les stratégies les plus classiques sont :\n - `schedule(static)` : découpe les indices en autant de blocs de même taille qu'il y a de *threads* ;\n - `schedule(static,N)` : découpe les indices en blocs de taille `N` et les distribue équitablement et cycliquement entre les *threads*  ;\n - `schedule(dynamic,N)` : découpe les indices en blocs de taille `N` et les attribue successivement aux *threads* au fur et à mesure qu'ils sont disponibles ;\n - `schedule(runtime)` : applique la stratégie décrite dans la variable d'environnement `OMP_SCHEDULE`."},{"metadata":{},"cell_type":"markdown","source":"À l'aide des deux variables `OMP_SCHEDULE` et `OMP_NUM_THREADS`, il est possible d'étudier l'influence de la stratégie de distributions d'indices et de chercher les meilleurs paramètres pour une machine donnée. C'est ce que proposent les scripts `bench`, pour collecter des statistiques, et `show`, pour afficher ces données sous forme de courbes de performance."},{"metadata":{},"cell_type":"markdown","source":"Si $T_S$ est le temps de calcul séquentiel et $T_P(p)$ le temps de calcul parallèle pour effectuer une tâche avec $p$ *threads*, on définit l'accélération comme la quantité $S^*(p) = \\frac{T_S}{T_P(p)}$ et l'efficacité comme $E^*(p) = \\frac{S^*(p)}{p}$.\n"},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"Q16. Modifiez votre programme pour utiliser `schedule(runtime)` sur les deux régions parallèles. Lire la fin du fichier `README.md`. Utilisez les scripts `bench` et `show` pour produire des courbes pertinentes. Il conviendra d'adapter le nombre de *threads*, le nombre d'itérations et l'image utilisée à votre machine.\n"},{"metadata":{},"cell_type":"markdown","source":"Si vous ne disposez pas des bibliothèques pour générer les courbes, vous pouvez les générer dans ce *notebook* en collant le contenu de `stats.csv` puis en exécutant les cellules ci-dessous.\n"},{"metadata":{"lines_to_next_cell":2,"trusted":false},"cell_type":"code","source":"from io import StringIO\nfrom ezplot import ezplot","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":2,"trusted":false},"cell_type":"code","source":"data=\"\"\"\n### COLLER A LA PLACE DE CETTE LIGNE LE CONTENU DE stats.csv\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":2,"trusted":false},"cell_type":"code","source":"ezplot(StringIO(data),['bs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ezplot(StringIO(data),['schedule'])","execution_count":null,"outputs":[]},{"metadata":{"tags":["question"]},"cell_type":"raw","source":"CHECK-POINT #2 <<<<<<< LORSQUE VOUS ATTEIGNEZ CETTE ENDROIT DE LA FICHE, APPELEZ VOTRE CHARGÉ DE TP ! >>>>>>>>"},{"metadata":{},"cell_type":"markdown","source":"## Références\n\n 1. [Spécification OpenMP](https://www.openmp.org/specifications/)\n 1. [OpenMP Reference Guide](https://www.openmp.org/resources/refguides/)\n 1. [Exemples de statistiques collectées pour la partie 2](?from=progpar/perf.ipynb&module=progpar/ezplot.py) !"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":2}